{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id  age     sex   region urban_rural   income     education  \\\n",
      "0      75722   52  Female    North    Suburban  22700.0     Doctorate   \n",
      "1      80185   79  Female    North       Urban  12800.0         No HS   \n",
      "2      19865   68    Male    North       Rural  40700.0            HS   \n",
      "3      76700   15    Male    North    Suburban  15600.0  Some College   \n",
      "4      92992   53    Male  Central    Suburban  89600.0     Doctorate   \n",
      "\n",
      "  marital_status employment_status  household_size  ...  liver_disease  \\\n",
      "0        Married           Retired               3  ...              0   \n",
      "1        Married          Employed               3  ...              0   \n",
      "2        Married           Retired               5  ...              0   \n",
      "3        Married     Self-employed               5  ...              0   \n",
      "4        Married     Self-employed               2  ...              0   \n",
      "\n",
      "   arthritis mental_health proc_imaging_count  proc_surgery_count  \\\n",
      "0          1             0                  1                   0   \n",
      "1          1             1                  0                   0   \n",
      "2          0             1                  1                   0   \n",
      "3          0             0                  1                   0   \n",
      "4          1             0                  2                   0   \n",
      "\n",
      "   proc_physio_count  proc_consult_count  proc_lab_count  is_high_risk  \\\n",
      "0                  2                   0               1             0   \n",
      "1                  1                   0               1             1   \n",
      "2                  2                   1               0             1   \n",
      "3                  0                   1               0             0   \n",
      "4                  1                   1               0             1   \n",
      "\n",
      "   had_major_procedure  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "Index(['person_id', 'age', 'sex', 'region', 'urban_rural', 'income',\n",
      "       'education', 'marital_status', 'employment_status', 'household_size',\n",
      "       'dependents', 'bmi', 'smoker', 'alcohol_freq', 'visits_last_year',\n",
      "       'hospitalizations_last_3yrs', 'days_hospitalized_last_3yrs',\n",
      "       'medication_count', 'systolic_bp', 'diastolic_bp', 'ldl', 'hba1c',\n",
      "       'plan_type', 'network_tier', 'deductible', 'copay', 'policy_term_years',\n",
      "       'policy_changes_last_2yrs', 'provider_quality', 'risk_score',\n",
      "       'annual_medical_cost', 'annual_premium', 'monthly_premium',\n",
      "       'claims_count', 'avg_claim_amount', 'total_claims_paid',\n",
      "       'chronic_count', 'hypertension', 'diabetes', 'asthma', 'copd',\n",
      "       'cardiovascular_disease', 'cancer_history', 'kidney_disease',\n",
      "       'liver_disease', 'arthritis', 'mental_health', 'proc_imaging_count',\n",
      "       'proc_surgery_count', 'proc_physio_count', 'proc_consult_count',\n",
      "       'proc_lab_count', 'is_high_risk', 'had_major_procedure'],\n",
      "      dtype='object')\n",
      "Features used: ['person_id', 'age', 'sex', 'region', 'urban_rural', 'income', 'education', 'marital_status', 'employment_status', 'household_size', 'dependents', 'bmi', 'smoker', 'alcohol_freq', 'visits_last_year', 'hospitalizations_last_3yrs', 'days_hospitalized_last_3yrs', 'medication_count', 'systolic_bp', 'diastolic_bp', 'ldl', 'hba1c', 'plan_type', 'network_tier', 'deductible', 'copay', 'policy_term_years', 'policy_changes_last_2yrs', 'provider_quality', 'risk_score', 'chronic_count', 'hypertension', 'diabetes', 'asthma', 'copd', 'cardiovascular_disease', 'cancer_history', 'kidney_disease', 'liver_disease', 'arthritis', 'mental_health', 'proc_imaging_count', 'proc_surgery_count', 'proc_physio_count', 'proc_consult_count', 'proc_lab_count', 'is_high_risk', 'had_major_procedure']\n",
      "Class distribution (train):\n",
      "premium_class\n",
      "low       0.333338\n",
      "medium    0.333338\n",
      "high      0.333325\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Baseline (most_frequent)\n",
      "------------------------\n",
      "Train accuracy: 0.333\n",
      "Test  accuracy: 0.333\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.00      0.00      0.00      6667\n",
      "         low       0.33      1.00      0.50      6666\n",
      "      medium       0.00      0.00      0.00      6667\n",
      "\n",
      "    accuracy                           0.33     20000\n",
      "   macro avg       0.11      0.33      0.17     20000\n",
      "weighted avg       0.11      0.33      0.17     20000\n",
      "\n",
      "Confusion matrix (test):\n",
      "[[   0 6667    0]\n",
      " [   0 6666    0]\n",
      " [   0 6667    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "-------------------\n",
      "Train accuracy: 0.495\n",
      "Test  accuracy: 0.496\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.54      0.59      0.57      6667\n",
      "         low       0.51      0.65      0.58      6666\n",
      "      medium       0.38      0.25      0.30      6667\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.48      0.50      0.48     20000\n",
      "weighted avg       0.48      0.50      0.48     20000\n",
      "\n",
      "Confusion matrix (test):\n",
      "[[3939 1361 1367]\n",
      " [1034 4346 1286]\n",
      " [2287 2740 1640]]\n",
      "\n",
      "Random Forest\n",
      "-------------\n",
      "Train accuracy: 0.905\n",
      "Test  accuracy: 0.489\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.52      0.61      0.56      6667\n",
      "         low       0.52      0.60      0.56      6666\n",
      "      medium       0.37      0.25      0.30      6667\n",
      "\n",
      "    accuracy                           0.49     20000\n",
      "   macro avg       0.47      0.49      0.48     20000\n",
      "weighted avg       0.47      0.49      0.48     20000\n",
      "\n",
      "Confusion matrix (test):\n",
      "[[4082 1180 1405]\n",
      " [1228 4015 1423]\n",
      " [2476 2503 1688]]\n",
      "\n",
      "KNN (k=7)\n",
      "---------\n",
      "Train accuracy: 0.576\n",
      "Test  accuracy: 0.429\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.46      0.50      0.48      6667\n",
      "         low       0.45      0.54      0.49      6666\n",
      "      medium       0.34      0.25      0.29      6667\n",
      "\n",
      "    accuracy                           0.43     20000\n",
      "   macro avg       0.42      0.43      0.42     20000\n",
      "weighted avg       0.42      0.43      0.42     20000\n",
      "\n",
      "Confusion matrix (test):\n",
      "[[3350 1728 1589]\n",
      " [1516 3580 1570]\n",
      " [2345 2669 1653]]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Imports\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Load data\n",
    "#    (make sure the filename matches what you downloaded)\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"medical_insurance.csv\")\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Choose a target and turn it into classes\n",
    "#    Here we assume 'annual_premium' is the cost column.\n",
    "#    If your file uses another name (e.g. 'PremiumPrice'),\n",
    "#    change TARGET_COL accordingly.\n",
    "# ============================================================\n",
    "TARGET_COL = \"annual_premium\"   # change if needed\n",
    "\n",
    "# create 3 classes based on quantiles: low / medium / high\n",
    "n_bins = 3\n",
    "df[\"premium_class\"] = pd.qcut(\n",
    "    df[TARGET_COL],\n",
    "    q=n_bins,\n",
    "    labels=[\"low\", \"medium\", \"high\"]\n",
    ")\n",
    "\n",
    "# This will be our classification target\n",
    "y = df[\"premium_class\"]\n",
    "\n",
    "# ============================================================\n",
    "# 4. Define feature matrix X\n",
    "#    Drop the target and any obvious leakage columns\n",
    "#    (you already did something similar in your regression code)\n",
    "# ============================================================\n",
    "cols_to_drop = [\n",
    "    TARGET_COL,\n",
    "    \"annual_medical_cost\",\n",
    "    \"monthly_premium\",\n",
    "    \"avg_claim_amount\",\n",
    "    \"total_claims_paid\",\n",
    "    \"claims_count\"\n",
    "]\n",
    "\n",
    "cols_to_drop = [c for c in cols_to_drop if c in df.columns]\n",
    "\n",
    "X = df.drop(columns=cols_to_drop + [\"premium_class\"])\n",
    "\n",
    "print(\"Features used:\", X.columns.tolist())\n",
    "\n",
    "# ============================================================\n",
    "# 5. Preprocessing: numeric + categorical\n",
    "# ============================================================\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numeric_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Train / test split\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Class distribution (train):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# ============================================================\n",
    "# 7. Helper function for evaluation\n",
    "# ============================================================\n",
    "def evaluate_classifier(name, model, X_train, X_test, y_train, y_test):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"-\" * len(name))\n",
    "    print(f\"Train accuracy: {acc_train:.3f}\")\n",
    "    print(f\"Test  accuracy: {acc_test:.3f}\")\n",
    "\n",
    "    print(\"\\nClassification report (test):\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    print(\"Confusion matrix (test):\")\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# ============================================================\n",
    "# 8. Baseline classifier (predicts majority class)\n",
    "# ============================================================\n",
    "baseline_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", DummyClassifier(strategy=\"most_frequent\"))\n",
    "])\n",
    "\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "evaluate_classifier(\"Baseline (most_frequent)\", baseline_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ============================================================\n",
    "# 9. Logistic Regression classifier\n",
    "# ============================================================\n",
    "log_reg = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, multi_class=\"multinomial\"))\n",
    "])\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "evaluate_classifier(\"Logistic Regression\", log_reg, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ============================================================\n",
    "# 10. Random Forest classifier\n",
    "# ============================================================\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "evaluate_classifier(\"Random Forest\", rf_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ============================================================\n",
    "# 11. K-Nearest Neighbors classifier\n",
    "# ============================================================\n",
    "knn_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=7))\n",
    "])\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "evaluate_classifier(\"KNN (k=7)\", knn_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ============================================================\n",
    "# 12. Support Vector Machine classifier\n",
    "# ============================================================\n",
    "svm_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "evaluate_classifier(\"SVM (RBF kernel)\", svm_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ============================================================\n",
    "# 13. Decision Tree classifier\n",
    "# ============================================================\n",
    "tree_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", DecisionTreeClassifier(\n",
    "        max_depth=5,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "tree_clf.fit(X_train, y_train)\n",
    "evaluate_classifier(\"Decision Tree\", tree_clf, X_train, X_test, y_train, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
